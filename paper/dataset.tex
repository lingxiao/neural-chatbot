We first trained the modified SEQ2SEQ model on the CALLHOME American English Speech corpus (LDC97S42), consisting of 120 of 30-minute phone conversations between native English speakers.The size of vocabulary we used is 8038. However, in most of the conversation datasets, one speaker talks a long sentence or several sentences in a row and the other speaker answers with one or two words such as \textit{"mhm"},\textit{"okay"}, and \textit{"yeah"} as shown in Table.\ref{table:phone_data}. In fact, about 20\% of the utterances of the dataset is \textit{"mhm"}. As a results, the trained model after 44200 steps generated a short answer for long input utterances and a long answer for short input utterances (Table.\ref{table:phone_result}). Therefore, we concluded that this dataset may not have been appropriate for learning a dialog generation model.

Instead, we used the OpenSubtitles corpus (http://www.opensubtitles.org/) for both HRED and DRL. The OpenSubtitles corpus is a bilingual parallel corpus composed of movie subtitles. Originally constructed for machine translation, it has 20,400 files with 149.44 million tokens and 22.27 million sentence fragments. We used the 28 documents with English counterparts. The corpus is preprocessed by removing all ASCII symbols and adding consecutive speaker turns in an ad-hoc manner, that is to say we defaulted the first line in the script to be that of speaker one, the second line to be speaker two, and so on. Next, the corpus was normalized by case-folding, white space stripping, and converting all tokens to lower cases. Proper nouns and numbers were kept as is. 

with 50005 vocabulary size. The DRL paper also used this dataset, but unlike the paper, we didn't extract \textit{"i don't know what you are talking about"}. Instead, we refined abbreviated words such as \textit{"i'm"} $\rightarrow$ \textit{"i am"}, {"you're"} $\rightarrow$ \textit{"you are"}, {"i've"} $\rightarrow$ \textit{"i have"}, {"wanna"} $\rightarrow$ \textit{"want to"}, {"gonna"} $\rightarrow$ \textit{"going to"}, {"don't"} $\rightarrow$ \textit{"do not"}, etc. 

\begin{table}[t!]
    \centering
    \small
    \caption{\small Example Conversation in the CALLHOME corpus}
    \begin{tabular}{rl}
      \hline
        \textbf{A:} & who is in um someone not that they have problems but\\
        		    & someone who's like an okay student but kind of on the\\
        			& borderline you know like maybe not a great homelife\\
        			& and we would ha i got paired up\\
		\textbf{B:} & uh-huh \\
\textbf{A:} & with someone at um lipsmack i forget the school it was\\
			& actually in port richmond um breath i forget the name\\
			& of the school\\\
\textbf{B:} & really\\
\textbf{A:} & hensfiel no it was in the philadelphia school system and\\ 
			& it it was a middle school\\
\textbf{B:} & mhm\\
      \hline
    \end{tabular}
    \label{table:phone_data}
\end{table}


\begin{table}[t!]
    \centering
    \small
    \caption{\small Example Conversation in the OpenSubtitles corpus}
    \begin{tabular}{rl}
      \hline
        \textbf{A:} & a proud rebellious son who was sold to living death in \\
                    & the mines of libya before his thirteenth birthday \\
        \textbf{B:} & there under whip and chain and sun he lived out his \\
                    & youth and his young manhood dreaming the death of slavery \\
                    & 2 000 years before it finally would die \\
\textbf{A:} & back to work\\
\textbf{B:} & get up spartacus you thracian dog\\
\textbf{A:} & come on get up\\ 
\textbf{B:} & my ankle my ankle\\
      \hline
    \end{tabular}
    \label{table:phone_data}
\end{table}