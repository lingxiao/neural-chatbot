\section{Introduction}
In recent years, various neural network based methods have demonstrated state of the art performance in automatic dialogue generation. Vinyals showed that a simple sequence to sequence (SEQ2SEQ) model mapping input utterances to output repsonses could learn to converse fluently in restricted domains \cite{Vinyals:15}. However this model often fails to capture long-term conversation histories, and does not consider influences of current responses on future outcomes. Therefore it often fails to maintain a coherent topic of converation and outputs short-sighted responses. Li showed that integrating SEQ2SEQ and reinforcement learning (DRL-SEQ2SEQ model) generated more interesting responses and thereby encouraged a longer dialogue session \cite{Li}. Serban improved topic coherence using a hierarchical recurrent encoder-decoder architecture (HRED), which incorporated conversation history to bias local probability of words within an utterance \cite{Serban:15}. In this paper, we propose a dialogue generation model using deep reinforcement learning (DRL) and HRED, thus incorporating the advantages of both models. We train the model on the CALLHOME American English Speech corpus (LDC97S42), consisting of 120 30-minute phone conversations between native English speakers.